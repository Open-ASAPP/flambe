!Experiment

name: sst-text-classification

pipeline:

  # stage 0 - Load the Stanford Sentiment Treebank dataset and run preprocessing
  dataset: !SSTDataset # this is a simple Python object, and the arguments to build it
    transform: # these arguments are passed to the init method
      text: !TextField
      label: !LabelField

  # Stage 1 - Define a model
  model: !TextClassifier
      embedder: !Embedder
        embedding: !torch.Embedding  # automatically use pytorch classes
          num_embeddings: !copy dataset.text.vocab_size # link to other components, and attributes
          embedding_dim: 300
        embedding_dropout: 0.3
        encoder: !PooledRNNEncoder
          input_size: 300
          n_layers: !choice [2, 3, 4] # grid search over any parameters
          hidden_size: 128
          rnn_type: sru
          dropout: 0.3
      output_layer: !SoftmaxLayer
          input_size: !ref model[embedder][encoder].rnn.hidden_size # also use inner-links
          output_size: !ref dataset.label.vocab_size

  # Stage 2 - Train the model on the dataset
  train: !Trainer
    dataset: !copy dataset
    model: !copy model
    train_sampler: !BaseSampler
    val_sampler: !BaseSampler
    loss_fn: !torch.NLLLoss
    metric_fn: !Accuracy
    optimizer: !torch.Adam
      params: !ref train[model].trainable_params
    max_steps: 2
    iter_per_step: 2

  # Stage 3 - Eval on the test set
  eval: !Evaluator
    dataset: !copy dataset
    model: !copy train[model]
    metric_fn: !Accuracy
    eval_sampler: !BaseSampler

# Define how to schedule variants
schedulers:
  train: !Hyperband
    max_steps: 2
    step_budget: 2