!Experiment

name: sst-text-classification

pipeline:

  train: !Trainer
    dataset: !SSTDataset # this is a simple Python object, and the arguments to build it
      transform: # these arguments are passed to the init method
        text: !TextField
        label: !LabelField
    model: !TextClassifier
      embedder: !Embedder
        embedding: !Embeddings  # automatically use pytorch classes
          num_embeddings: !@ train[dataset].text.vocab_size # link to other components, and attributes
          embedding_dim: 300
        embedding_dropout: 0.3
        encoder: !PooledRNNEncoder
          input_size: 300
          n_layers: 2
          hidden_size: 128
          rnn_type: sru
          dropout: 0.3
      output_layer: !SoftmaxLayer
          input_size: !@ train[model][embedder][encoder].rnn.hidden_size # also use inner-links
          output_size: !@ train[dataset].label.vocab_size
    train_sampler: !BaseSampler
    val_sampler: !BaseSampler
    loss_fn: !torch.NLLLoss
    metric_fn: !Accuracy
    optimizer: !Adam
      params: !@ train[model].trainable_params
    max_steps: 2
    iter_per_step: 2

# Define how to schedule variants
# algorithm:
#     train: !RandomSearch
#       trial_budget: 1
#   train: !Hyperband
