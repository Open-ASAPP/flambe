!Experiment

name: bert

pipeline:
  dataset: !TabularDataset.from_path
    train_path: {top_level}/tests/data/dummy_tabular/train.csv
    val_path: {top_level}/tests/data/dummy_tabular/val.csv
    sep: ','
    transform:
      text: !BertTextField
        alias: 'bert-base-uncased'
      label: !LabelField

  teacher: !TextClassifier
    embedder: !BertEmbedder
      alias: 'bert-base-uncased'
      pool: True
    output_layer: !SoftmaxLayer
      input_size: !@ teacher[embedder].hidden_size
      output_size: !@ dataset.label.vocab_size

  finetune: !Trainer
    dataset: !@ dataset
    train_sampler: !BaseSampler
      batch_size: 16
    val_sampler: !BaseSampler
      batch_size: 16
    model: !@ teacher
    loss_fn: !torch.NLLLoss
    metric_fn: !Accuracy
    optimizer: !AdamW
      params: !@ finetune[model].trainable_params
      lr: 0.00005
    max_steps: 1
    iter_per_step: 1
